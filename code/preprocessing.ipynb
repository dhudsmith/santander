{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Preprocessing\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></div><div class=\"lev2\"><a href=\"#Imports-and-loading-the-data\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports and loading the data</a></div><div class=\"lev2\"><a href=\"#Cleaning-the-data\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Cleaning the data</a></div><div class=\"lev3\"><a href=\"#Remove-constant-a-duplicate-columns\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Remove constant a duplicate columns</a></div><div class=\"lev3\"><a href=\"#Save-the-IDs-and-TARGETs-and-drop-them-from-the-dataframe\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Save the IDs and TARGETs and drop them from the dataframe</a></div><div class=\"lev3\"><a href=\"#Pay-close-attention-to-the-important-features\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Pay close attention to the important features</a></div><div class=\"lev1\"><a href=\"#Feature-grooming\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Feature grooming</a></div><div class=\"lev2\"><a href=\"#var38\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>var38</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Imports and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-04-08T12:07:03.257Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Input data files are available in the \"./input/\" directory.\n",
    "# load data\n",
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "# load feature importances generated form \"random-forest.ipynb\"\n",
    "df_features = pd.read_csv('../misc/features_random_forest_20160408_062851.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "### Remove constant a duplicate columns\n",
    "We remove any constant columns and any duplicated columns (identical values) as these can have no signature in the dependent variable. Note that we remove the constant and duplicate columns in the training set **and the test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-04-08T12:07:03.259Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the IDs and TARGETs and drop them from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-04-08T12:07:03.261Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IDs = df_train[\"ID\"]\n",
    "IDs_test = df_test[\"ID\"]\n",
    "TARGETs = df_train[\"TARGET\"]\n",
    "\n",
    "df_train.drop([\"ID\", \"TARGET\"], axis=1, inplace=True)\n",
    "df_test.drop([\"ID\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pay close attention to the important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now examine the questions:\n",
    "1. Do the important features have missing values?\n",
    "2. Can any of the important features be split?\n",
    "\n",
    "As an example of the second question, if a feature takes a \"special\" value many more times than any other value, that feature can be split into two features:\n",
    "1. A binary feature (0/1), representing whether or not a record takes the \"special\"\n",
    "2. A feature that equals the original feature unless the special value obtains, in which case it is zero. \n",
    "Below, we show that \"var38\", which ranked top in our random forest classification can be split into two features. Since it ranked so highly, this may be worth our time.\n",
    "\n",
    "To try to answer questions 1. and 2., we examine the value counts for the top 'n_features' features. This can give us hints about missing values (extreme outliers) as well as suggestions about splitting variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-04-08T12:07:03.264Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = 40\n",
    "df_features_keep = df_features.iloc[0:n_features,:]\n",
    "\n",
    "df_train_keep = df_train[df_features_keep[\"Feature\"]]\n",
    "\n",
    "\n",
    "for i in range(0,n_features):\n",
    "    print(df_train_keep[df_features_keep[\"Feature\"][i]].value_counts().iloc[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following discussion, we go up to \"n_features\" = 40. Carefully looking through the value counts we find:\n",
    "1. var38: should be split in the manner described above\n",
    "2. num_var22_hace2: this feature obtains values 0,1,2,3,99. With many entries equal to 99. I expect that 99 is a missing value. We can deal with this by splitting in the manner described above.\n",
    "3. imp_op_var_39_efect_ult3: This feature has\n",
    "    * a clear outlier, -999999, almost certainly representing missing value. Since not so many are missing, we can probably safely replace -999999 --> 2 (the most common value)\n",
    "    * a dominant mode (2). This variable can be split in the manner described above.\n",
    "\n",
    "We also note that lots of variables have zero as the dominant mode. Some of these should perhaps be split, but without knowing the meaning of the variables, it's hard to know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature grooming\n",
    "We will now implement the changes suggested in points 1 through 3 above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## var38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-04-08T12:07:03.267Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mode = df_train_keep.var38.mode()\n",
    "df_train_keep['var38mode']=np.isclose(df_train.var38, mode)\n",
    "print(df_train_keep['var38mode'].value_counts())\n",
    "\n",
    "df_train_keep.loc[df_train_keep[\"var38mode\"], \"var38\"]=0\n",
    "print(df_train_keep['var38'].value_counts().iloc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
