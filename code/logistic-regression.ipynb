{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Preprocessing\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></div><div class=\"lev2\"><a href=\"#Imports-and-loading-the-data\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports and loading the data</a></div><div class=\"lev2\"><a href=\"#Cleaning-the-data\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Cleaning the data</a></div><div class=\"lev3\"><a href=\"#Remove-constant-a-duplicate-columns\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Remove constant a duplicate columns</a></div><div class=\"lev3\"><a href=\"#Save-the-IDs-and-TARGETs-and-drop-them-from-the-dataframe\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Save the IDs and TARGETs and drop them from the dataframe</a></div><div class=\"lev1\"><a href=\"#Logistic-regression\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Logistic regression</a></div><div class=\"lev1\"><a href=\"#Output\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Output</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Imports and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T21:29:01.598580",
     "start_time": "2016-04-07T21:28:50.029649"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Input data files are available in the \"./input/\" directory.\n",
    "# load data\n",
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "### Remove constant a duplicate columns\n",
    "We remove any constant columns and any duplicated columns (identical values) as these can have no signature in the dependent variable. Note that we remove the constant and duplicate columns in the training set **and the test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T21:29:09.233122",
     "start_time": "2016-04-07T21:29:01.601377"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the IDs and TARGETs and drop them from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T21:29:09.499060",
     "start_time": "2016-04-07T21:29:09.236003"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IDs = df_train[\"ID\"]\n",
    "IDs_test = df_test[\"ID\"]\n",
    "TARGETs = df_train[\"TARGET\"]\n",
    "\n",
    "df_train.drop([\"ID\", \"TARGET\"], axis=1, inplace=True)\n",
    "df_test.drop([\"ID\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T21:42:02.001264",
     "start_time": "2016-04-07T21:41:39.622479"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhudsonsmith/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72977    35]\n",
      " [ 2996    12]]\n",
      "Overall AUC: 0.473699815704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "X, y = df_train, TARGETs\n",
    "\n",
    "n_features = 40 #Only use the top 'n_features' features\n",
    "weights = {0: 1, 1: 2} #Attempt to balance the classes\n",
    "clf = Pipeline([\n",
    "        ('remove_zero_variance', VarianceThreshold()),\n",
    "        ('feature_selection', SelectKBest(f_classif, k=n_features)),\n",
    "        ('classification', LogisticRegression(penalty = \"l2\", \n",
    "                                              solver = \"sag\",\n",
    "                                              max_iter = 500,\n",
    "                                              tol = 0.001,\n",
    "                                              n_jobs=4, C=1,\n",
    "                                              class_weight = weights, \n",
    "                                              warm_start = False\n",
    "                                       ))\n",
    "])\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_test_pred = clf.predict(X)\n",
    "\n",
    "# Test on the training set:\n",
    "y_test_pred = clf.predict(X)\n",
    "print(confusion_matrix(TARGETs, y_test_pred))\n",
    "\n",
    "# Calculate the roc_auc score\n",
    "print('Overall AUC:', roc_auc_score(y, clf.predict_proba(X)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T21:29:13.174502",
     "start_time": "2016-04-07T21:29:12.625242"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "y_probs = clf.predict_proba(df_test)[:,1]\n",
    "\n",
    "# Stamp the output with the current time\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "submission = pd.DataFrame({\"ID\":IDs_test, \"TARGET\":y_probs})\n",
    "submission.to_csv(\"../results/logistic_reg_\" + timestamp + \".csv\", index=False, float_format=\"%10.8f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
