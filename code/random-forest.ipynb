{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Preprocessing\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></div><div class=\"lev2\"><a href=\"#Imports-and-loading-the-data\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports and loading the data</a></div><div class=\"lev2\"><a href=\"#Cleaning-the-data\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Cleaning the data</a></div><div class=\"lev3\"><a href=\"#Remove-constant-a-duplicate-columns\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Remove constant a duplicate columns</a></div><div class=\"lev3\"><a href=\"#Save-the-IDs-and-TARGETs-and-drop-them-from-the-dataframe\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Save the IDs and TARGETs and drop them from the dataframe</a></div><div class=\"lev1\"><a href=\"#Random-Forest\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Random Forest</a></div><div class=\"lev1\"><a href=\"#Output\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Output</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Imports and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T21:02:46.958572",
     "start_time": "2016-04-07T21:02:38.065629"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Input data files are available in the \"./input/\" directory.\n",
    "# load data\n",
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "### Remove constant a duplicate columns\n",
    "We remove any constant columns and any duplicated columns (identical values) as these can have no signature in the dependent variable. Note that we remove the constant and duplicate columns in the training set **and the test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T21:02:54.586540",
     "start_time": "2016-04-07T21:02:46.960592"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the IDs and TARGETs and drop them from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T21:02:54.756251",
     "start_time": "2016-04-07T21:02:54.591433"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IDs = df_train[\"ID\"]\n",
    "IDs_test = df_test[\"ID\"]\n",
    "TARGETs = df_train[\"TARGET\"]\n",
    "\n",
    "df_train.drop([\"ID\", \"TARGET\"], axis=1, inplace=True)\n",
    "df_test.drop([\"ID\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Promising results. Computationally expensive, because we have so many features. We need the number of trees to be significantly larger than the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T21:08:12.031989",
     "start_time": "2016-04-07T21:06:13.369079"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72794   218]\n",
      " [  208  2800]]\n",
      "Overall AUC: 0.998815094772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "X, y = df_train, TARGETs\n",
    "\n",
    "n_features = 'all' #Only use the top 'n_features' features\n",
    "n_estimators = 500 #Number of trees\n",
    "weights = {0: 1, 1:3.45} #Attempt to balance the classes\n",
    "clf = Pipeline([\n",
    "        ('remove_zero_variance', VarianceThreshold()),\n",
    "        ('feature_selection', SelectKBest(f_classif, k=n_features)),\n",
    "        ('classification', RandomForestClassifier(n_estimators,\n",
    "                                                max_features = 40,\n",
    "                                                n_jobs=4,\n",
    "                                                class_weight= weights,\n",
    "                                                warm_start=False))\n",
    "])\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_test_pred = clf.predict(X)\n",
    "\n",
    "# Test on the training set:\n",
    "y_test_pred = clf.predict(X)\n",
    "print(confusion_matrix(TARGETs, y_test_pred))\n",
    "\n",
    "# Calculate the roc_auc score\n",
    "print('Overall AUC:', roc_auc_score(y, clf.predict_proba(X)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those numbers don't look too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T21:19:36.622787",
     "start_time": "2016-04-07T21:19:31.710750"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "y_probs = clf.predict_proba(df_test)[:,1]\n",
    "\n",
    "# Stamp the output with the current time\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "submission = pd.DataFrame({\"ID\":IDs_test, \"TARGET\":y_probs})\n",
    "submission.to_csv(\"../results/random_forest_\" + timestamp + \".csv\", index=False, float_format=\"%10.8f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
