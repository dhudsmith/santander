{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Preprocessing\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></div><div class=\"lev2\"><a href=\"#Imports-and-loading-the-data\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports and loading the data</a></div><div class=\"lev2\"><a href=\"#Cleaning-the-data\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Cleaning the data</a></div><div class=\"lev3\"><a href=\"#Remove-constant-a-duplicate-columns\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Remove constant a duplicate columns</a></div><div class=\"lev3\"><a href=\"#Save-the-IDs-and-TARGETs-and-drop-them-from-the-dataframe\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Save the IDs and TARGETs and drop them from the dataframe</a></div><div class=\"lev1\"><a href=\"#Random-Forest\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Random Forest</a></div><div class=\"lev1\"><a href=\"#Output\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Output</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Imports and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-08T06:09:45.712044",
     "start_time": "2016-04-08T06:09:35.066325"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Input data files are available in the \"./input/\" directory.\n",
    "# load data\n",
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "### Remove constant a duplicate columns\n",
    "We remove any constant columns and any duplicated columns (identical values) as these can have no signature in the dependent variable. Note that we remove the constant and duplicate columns in the training set **and the test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-08T06:09:52.999054",
     "start_time": "2016-04-08T06:09:45.714587"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the IDs and TARGETs and drop them from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-08T06:09:53.218923",
     "start_time": "2016-04-08T06:09:53.001480"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IDs = df_train[\"ID\"]\n",
    "IDs_test = df_test[\"ID\"]\n",
    "TARGETs = df_train[\"TARGET\"]\n",
    "\n",
    "df_train.drop([\"ID\", \"TARGET\"], axis=1, inplace=True)\n",
    "df_test.drop([\"ID\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Promising results. Computationally expensive, because we have so many features. We need the number of trees to be significantly larger than the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-08T06:11:43.210813",
     "start_time": "2016-04-08T06:09:53.221250"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72846   166]\n",
      " [  224  2784]]\n",
      "Overall AUC: 0.998808656381\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "X, y = df_train, TARGETs\n",
    "\n",
    "n_features = 'all' #Only use the top 'n_features' features\n",
    "n_estimators = 500 #Number of trees\n",
    "weights = {0: 1, 1:3.45} #Attempt to balance the classes\n",
    "clf = Pipeline([\n",
    "        ('remove_zero_variance', VarianceThreshold()),\n",
    "        ('feature_selection', SelectKBest(f_classif, k=n_features)),\n",
    "        ('classification', RandomForestClassifier(n_estimators,\n",
    "                                                max_features = 40,\n",
    "                                                n_jobs=4,\n",
    "                                                class_weight= weights,\n",
    "                                                warm_start=False))\n",
    "])\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_test_pred = clf.predict(X)\n",
    "\n",
    "# Test on the training set:\n",
    "y_test_pred = clf.predict(X)\n",
    "print(confusion_matrix(TARGETs, y_test_pred))\n",
    "\n",
    "# Calculate the roc_auc score\n",
    "print('Overall AUC:', roc_auc_score(y, clf.predict_proba(X)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those numbers don't look too bad. While we have our model. Let's see what the important factors are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-08T06:45:30.040117",
     "start_time": "2016-04-08T06:45:29.818016"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature  Importance\n",
      "305                   var38    1.000000\n",
      "1                     var15    0.655383\n",
      "270   saldo_medio_var5_ult3    0.111242\n",
      "268  saldo_medio_var5_hace3    0.103625\n",
      "143             saldo_var30    0.094445\n",
      "266          num_var45_ult3    0.068516\n",
      "267  saldo_medio_var5_hace2    0.066033\n",
      "150             saldo_var42    0.063755\n",
      "264         num_var45_hace3    0.055194\n",
      "269   saldo_medio_var5_ult1    0.054414\n",
      "221          num_var22_ult3    0.048071\n",
      "128              saldo_var5    0.046764\n",
      "263         num_var45_hace2    0.046704\n",
      "265          num_var45_ult1    0.033356\n",
      "219         num_var22_hace3    0.033277\n",
      "224     num_meses_var5_ult3    0.031059\n",
      "218         num_var22_hace2    0.030720\n",
      "152                   var36    0.029828\n",
      "223      num_med_var45_ult3    0.029616\n",
      "109               num_var30    0.029137\n"
     ]
    }
   ],
   "source": [
    "feature_importances = clf.named_steps[\"classification\"].feature_importances_\n",
    "relative_importance = feature_importances/max(feature_importances)\n",
    "feature_IDs = df_test.columns.values\n",
    "\n",
    "feature_df = pd.DataFrame({\"Feature\":feature_IDs, \"Importance\":relative_importance}).sort_values(by=\"Importance\", \n",
    "                                                                                                 ascending = False)\n",
    "print(feature_df.iloc[0:20,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top features here all show up in the analysis performed by \"Selfish Gene\":\n",
    "https://www.kaggle.com/selfishgene/santander-customer-satisfaction/advanced-feature-exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-08T06:28:51.521607",
     "start_time": "2016-04-08T06:28:46.397334"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "y_probs = clf.predict_proba(df_test)[:,1]\n",
    "\n",
    "# Stamp the output with the current time\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Output the submission\n",
    "submission = pd.DataFrame({\"ID\":IDs_test, \"TARGET\":y_probs})\n",
    "submission.to_csv(\"../results/random_forest_\" + timestamp + \".csv\", \n",
    "                  index=False, float_format=\"%10.8f\")\n",
    "\n",
    "# Output the important features\n",
    "feature_df.to_csv(\"../misc/features_random_forest_\" + timestamp + \".csv\", \n",
    "                  index=False, float_format=\"%8.6f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
