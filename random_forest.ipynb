{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Preprocessing\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></div><div class=\"lev2\"><a href=\"#Imports-and-loading-the-data\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports and loading the data</a></div><div class=\"lev2\"><a href=\"#Cleaning-the-data\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Cleaning the data</a></div><div class=\"lev3\"><a href=\"#Remove-constant-a-duplicate-columns\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Remove constant a duplicate columns</a></div><div class=\"lev3\"><a href=\"#Save-the-IDs-and-TARGETs-and-drop-them-from-the-dataframe\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Save the IDs and TARGETs and drop them from the dataframe</a></div><div class=\"lev3\"><a href=\"#Look-for-outliers-and-missing-values\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Look for outliers and missing values</a></div><div class=\"lev1\"><a href=\"#Feature-Analysis\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Feature Analysis</a></div><div class=\"lev2\"><a href=\"#Select-K-Best\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Select K Best</a></div><div class=\"lev2\"><a href=\"#Select-false-discovery-rate\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Select false discovery rate</a></div><div class=\"lev2\"><a href=\"#Select-false-positive-rate\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Select false positive rate</a></div><div class=\"lev2\"><a href=\"#Select-family-wise-error-rates\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Select family-wise error rates</a></div><div class=\"lev1\"><a href=\"#Classification\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Classification</a></div><div class=\"lev2\"><a href=\"#Basic-Logistic-Regression\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Basic Logistic Regression</a></div><div class=\"lev2\"><a href=\"#Random-Forest\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Random Forest</a></div><div class=\"lev1\"><a href=\"#Outputting-the-result\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Outputting the result</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Imports and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:42:57.809744",
     "start_time": "2016-04-07T20:42:43.156423"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3   ...    \\\n",
       "0                      0.0                      0.0   ...     \n",
       "1                      0.0                      0.0   ...     \n",
       "2                      0.0                      0.0   ...     \n",
       "3                      0.0                      0.0   ...     \n",
       "4                      0.0                      0.0   ...     \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Input data files are available in the \"./input/\" directory.\n",
    "# load data\n",
    "df_train = pd.read_csv('./input/train.csv')\n",
    "df_test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "### Remove constant a duplicate columns\n",
    "We remove any constant columns and any duplicated columns (identical values) as these can have no signature in the dependent variable. Note that we remove the constant and duplicate columns in the training set **and the test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:43:05.274671",
     "start_time": "2016-04-07T20:42:57.811682"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the IDs and TARGETs and drop them from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:43:05.539133",
     "start_time": "2016-04-07T20:43:05.277100"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0     2     23                 0.0                      0.0   \n",
       "1     2     34                 0.0                      0.0   \n",
       "2     2     23                 0.0                      0.0   \n",
       "3     2     37                 0.0                    195.0   \n",
       "4     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  \\\n",
       "0                      0.0                      0.0                0.0   \n",
       "1                      0.0                      0.0                0.0   \n",
       "2                      0.0                      0.0                0.0   \n",
       "3                      0.0                      0.0                0.0   \n",
       "4                      0.0                      0.0                0.0   \n",
       "\n",
       "       ...        saldo_medio_var29_ult3  saldo_medio_var33_hace2  \\\n",
       "0      ...                           0.0                      0.0   \n",
       "1      ...                           0.0                      0.0   \n",
       "2      ...                           0.0                      0.0   \n",
       "3      ...                           0.0                      0.0   \n",
       "4      ...                           0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var33_hace3  saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "0                      0.0                     0.0                     0.0   \n",
       "1                      0.0                     0.0                     0.0   \n",
       "2                      0.0                     0.0                     0.0   \n",
       "3                      0.0                     0.0                     0.0   \n",
       "4                      0.0                     0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var44_hace2  saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var44_ult3          var38  \n",
       "0                     0.0   39205.170000  \n",
       "1                     0.0   49278.030000  \n",
       "2                     0.0   67333.770000  \n",
       "3                     0.0   64007.970000  \n",
       "4                     0.0  117310.979016  \n",
       "\n",
       "[5 rows x 306 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDs = df_train[\"ID\"]\n",
    "IDs_test = df_test[\"ID\"]\n",
    "TARGETs = df_train[\"TARGET\"]\n",
    "\n",
    "df_train.drop([\"ID\", \"TARGET\"], axis=1, inplace=True)\n",
    "df_test.drop([\"ID\"], axis=1, inplace=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for outliers and missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we work hard to remove outliers and missing values, we should perform a rough feature extraction to determine which columns are important. We can then focus on cleaning up those columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis\n",
    "Now we are left with a training data set containing 306 independent variables. We somehow have to determine which of these affect customer satisfaction. Here we try a few different feature selection tests based on the ANOVA F-value and compare the results. This is a univariate test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:43:05.545033",
     "start_time": "2016-04-07T20:43:05.541252"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = df_train, TARGETs\n",
    "n_factors = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:43:06.396900",
     "start_time": "2016-04-07T20:43:05.546788"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>   (76020, 20)\n",
      "                                 Feature      Score       p-value\n",
      "ind_var30                      ind_var30          1             0\n",
      "num_meses_var5_ult3  num_meses_var5_ult3   0.978848             0\n",
      "num_var30                      num_var30   0.849217  3.83395e-321\n",
      "num_var42                      num_var42   0.817038  3.61245e-309\n",
      "ind_var5                        ind_var5   0.812819  1.34417e-307\n",
      "num_var5                        num_var5   0.797562  6.45245e-302\n",
      "var36                              var36   0.466311  4.63701e-178\n",
      "var15                              var15   0.451801  1.30228e-172\n",
      "num_var4                        num_var4   0.281929  1.13782e-108\n",
      "num_var35                      num_var35   0.258924  5.48092e-100\n",
      "ind_var8_0                    ind_var8_0  0.0950596   6.36386e-38\n",
      "num_var8_0                    num_var8_0  0.0948828   7.42947e-38\n",
      "ind_var13                      ind_var13  0.0684528   8.67724e-28\n",
      "ind_var13_0                  ind_var13_0  0.0679647   1.33227e-27\n",
      "num_var13                      num_var13   0.064322   3.27168e-26\n",
      "ind_var12_0                  ind_var12_0  0.0637028   5.63828e-26\n",
      "num_var13_0                  num_var13_0  0.0631363   9.27684e-26\n",
      "saldo_var30                  saldo_var30  0.0600096    1.4505e-24\n",
      "ind_var39_0                  ind_var39_0  0.0535612   4.22974e-22\n",
      "ind_var13_corto          ind_var13_corto  0.0517193   2.14266e-21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "selector = SelectKBest(f_classif, k=n_factors)\n",
    "selector.fit(X,y)\n",
    "X_kbest = X.loc[:,selector.get_support()] # Subset the original data frame\n",
    "print(type(X), \" \", X_kbest.shape)\n",
    "\n",
    "kbest_results = np.transpose([X_kbest.columns.values, \n",
    "                        selector.scores_[selector.get_support()]/max(selector.scores_[selector.get_support()]), \n",
    "                        selector.pvalues_[selector.get_support()]])\n",
    "\n",
    "kbest_results_df = pd.DataFrame(kbest_results, \n",
    "                          index= kbest_results[:,0], \n",
    "                          columns = [\"Feature\", \"Score\", \"p-value\"]).sort_values(\"Score\", ascending = False)\n",
    "\n",
    "print(kbest_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select false discovery rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:43:07.211972",
     "start_time": "2016-04-07T20:43:06.398865"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>   (76020, 169)\n",
      "                                 Feature      Score       p-value\n",
      "ind_var30                      ind_var30          1             0\n",
      "num_meses_var5_ult3  num_meses_var5_ult3   0.978848             0\n",
      "num_var30                      num_var30   0.849217  3.83395e-321\n",
      "num_var42                      num_var42   0.817038  3.61245e-309\n",
      "ind_var5                        ind_var5   0.812819  1.34417e-307\n",
      "num_var5                        num_var5   0.797562  6.45245e-302\n",
      "var36                              var36   0.466311  4.63701e-178\n",
      "var15                              var15   0.451801  1.30228e-172\n",
      "num_var4                        num_var4   0.281929  1.13782e-108\n",
      "num_var35                      num_var35   0.258924  5.48092e-100\n",
      "ind_var8_0                    ind_var8_0  0.0950596   6.36386e-38\n",
      "num_var8_0                    num_var8_0  0.0948828   7.42947e-38\n",
      "ind_var13                      ind_var13  0.0684528   8.67724e-28\n",
      "ind_var13_0                  ind_var13_0  0.0679647   1.33227e-27\n",
      "num_var13                      num_var13   0.064322   3.27168e-26\n",
      "ind_var12_0                  ind_var12_0  0.0637028   5.63828e-26\n",
      "num_var13_0                  num_var13_0  0.0631363   9.27684e-26\n",
      "saldo_var30                  saldo_var30  0.0600096    1.4505e-24\n",
      "ind_var39_0                  ind_var39_0  0.0535612   4.22974e-22\n",
      "ind_var13_corto          ind_var13_corto  0.0517193   2.14266e-21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFdr, f_classif\n",
    "\n",
    "alpha = 0.01 # upper bound on est. false discovery rate\n",
    "selector = SelectFdr(f_classif, alpha = 0.5)\n",
    "selector.fit(X,y)\n",
    "X_fdr= X.loc[:,selector.get_support()] # Subset the original data frame\n",
    "print(type(X), \" \", X_fdr.shape)\n",
    "\n",
    "fdr_results = np.transpose([X_fdr.columns.values, \n",
    "                        selector.scores_[selector.get_support()]/max(selector.scores_[selector.get_support()]), \n",
    "                        selector.pvalues_[selector.get_support()]])\n",
    "\n",
    "fdr_results_df = pd.DataFrame(fdr_results, \n",
    "                          index= fdr_results[:,0], \n",
    "                          columns = [\"Feature\", \"Score\", \"p-value\"]).sort_values(\"Score\", ascending = False)\n",
    "\n",
    "print(fdr_results_df.iloc[0:n_factors,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select false positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:43:08.038567",
     "start_time": "2016-04-07T20:43:07.214949"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>   (76020, 201)\n",
      "                                 Feature      Score       p-value\n",
      "ind_var30                      ind_var30          1             0\n",
      "num_meses_var5_ult3  num_meses_var5_ult3   0.978848             0\n",
      "num_var30                      num_var30   0.849217  3.83395e-321\n",
      "num_var42                      num_var42   0.817038  3.61245e-309\n",
      "ind_var5                        ind_var5   0.812819  1.34417e-307\n",
      "num_var5                        num_var5   0.797562  6.45245e-302\n",
      "var36                              var36   0.466311  4.63701e-178\n",
      "var15                              var15   0.451801  1.30228e-172\n",
      "num_var4                        num_var4   0.281929  1.13782e-108\n",
      "num_var35                      num_var35   0.258924  5.48092e-100\n",
      "ind_var8_0                    ind_var8_0  0.0950596   6.36386e-38\n",
      "num_var8_0                    num_var8_0  0.0948828   7.42947e-38\n",
      "ind_var13                      ind_var13  0.0684528   8.67724e-28\n",
      "ind_var13_0                  ind_var13_0  0.0679647   1.33227e-27\n",
      "num_var13                      num_var13   0.064322   3.27168e-26\n",
      "ind_var12_0                  ind_var12_0  0.0637028   5.63828e-26\n",
      "num_var13_0                  num_var13_0  0.0631363   9.27684e-26\n",
      "saldo_var30                  saldo_var30  0.0600096    1.4505e-24\n",
      "ind_var39_0                  ind_var39_0  0.0535612   4.22974e-22\n",
      "ind_var13_corto          ind_var13_corto  0.0517193   2.14266e-21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFpr, f_classif\n",
    "\n",
    "alpha = 0.01 # upper bound on est. false positive rate\n",
    "selector = SelectFpr(f_classif, alpha = 0.5)\n",
    "selector.fit(X,y)\n",
    "X_fpr= X.loc[:,selector.get_support()] # Subset the original data frame\n",
    "print(type(X), \" \", X_fpr.shape)\n",
    "\n",
    "fpr_results = np.transpose([X_fpr.columns.values, \n",
    "                        selector.scores_[selector.get_support()]/max(selector.scores_[selector.get_support()]), \n",
    "                        selector.pvalues_[selector.get_support()]])\n",
    "\n",
    "fpr_results_df = pd.DataFrame(fpr_results, \n",
    "                          index= fpr_results[:,0], \n",
    "                          columns = [\"Feature\", \"Score\", \"p-value\"]).sort_values(\"Score\", ascending = False)\n",
    "\n",
    "print(fpr_results_df.iloc[0:n_factors,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select family-wise error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:43:08.773885",
     "start_time": "2016-04-07T20:43:08.040531"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>   (76020, 102)\n",
      "                                 Feature      Score       p-value\n",
      "ind_var30                      ind_var30          1             0\n",
      "num_meses_var5_ult3  num_meses_var5_ult3   0.978848             0\n",
      "num_var30                      num_var30   0.849217  3.83395e-321\n",
      "num_var42                      num_var42   0.817038  3.61245e-309\n",
      "ind_var5                        ind_var5   0.812819  1.34417e-307\n",
      "num_var5                        num_var5   0.797562  6.45245e-302\n",
      "var36                              var36   0.466311  4.63701e-178\n",
      "var15                              var15   0.451801  1.30228e-172\n",
      "num_var4                        num_var4   0.281929  1.13782e-108\n",
      "num_var35                      num_var35   0.258924  5.48092e-100\n",
      "ind_var8_0                    ind_var8_0  0.0950596   6.36386e-38\n",
      "num_var8_0                    num_var8_0  0.0948828   7.42947e-38\n",
      "ind_var13                      ind_var13  0.0684528   8.67724e-28\n",
      "ind_var13_0                  ind_var13_0  0.0679647   1.33227e-27\n",
      "num_var13                      num_var13   0.064322   3.27168e-26\n",
      "ind_var12_0                  ind_var12_0  0.0637028   5.63828e-26\n",
      "num_var13_0                  num_var13_0  0.0631363   9.27684e-26\n",
      "saldo_var30                  saldo_var30  0.0600096    1.4505e-24\n",
      "ind_var39_0                  ind_var39_0  0.0535612   4.22974e-22\n",
      "ind_var13_corto          ind_var13_corto  0.0517193   2.14266e-21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFwe, f_classif\n",
    "\n",
    "alpha = 0.01 # upper bound on est. false positive rate\n",
    "selector = SelectFwe(f_classif, alpha = 0.5)\n",
    "selector.fit(X,y)\n",
    "X_Fwe= X.loc[:,selector.get_support()] # Subset the original data frame\n",
    "print(type(X), \" \", X_Fwe.shape)\n",
    "\n",
    "Fwe_results = np.transpose([X_Fwe.columns.values, \n",
    "                        selector.scores_[selector.get_support()]/max(selector.scores_[selector.get_support()]), \n",
    "                        selector.pvalues_[selector.get_support()]])\n",
    "\n",
    "Fwe_results_df = pd.DataFrame(Fwe_results, \n",
    "                          index= Fwe_results[:,0], \n",
    "                          columns = [\"Feature\", \"Score\", \"p-value\"]).sort_values(\"Score\", ascending = False)\n",
    "\n",
    "print(Fwe_results_df.iloc[0:n_factors,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification\n",
    "All of these tests yield the same best features. That gives some confidence that at least some of these factors are quite important. To streamline the process, we will use scikit-learn's pipeline interface. We will try a few different classifier algorithms and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:43:08.788569",
     "start_time": "2016-04-07T20:43:08.775969"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Logistic Regression\n",
    "Doesn't seem to work so well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:43:16.110804",
     "start_time": "2016-04-07T20:43:08.790850"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48388, 24624],\n",
       "       [  778,  2230]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "n_features = 50\n",
    "clf = Pipeline([\n",
    "  ('feature_selection', SelectKBest(f_classif, k=n_features)),\n",
    "  ('classification', LogisticRegression(penalty = \"l2\", n_jobs=4, C=1,\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        warm_start = False\n",
    "                                       ))\n",
    "])\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Test on the training set:\n",
    "y_test_pred = clf.predict(X)\n",
    "confusion_matrix(TARGETs, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Promising results. Computationally expensive, because we have so many features. We need the number of trees to be significantly larger than the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:44:58.153181",
     "start_time": "2016-04-07T20:43:16.112817"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72841   171]\n",
      " [  223  2785]]\n",
      "Overall AUC: 0.998818272987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "n_features = 'all' #Only use the top 'n_features' features\n",
    "n_estimators = 500 #Number of trees\n",
    "weights = {0: 1, 1:3.45} #Attempt to balance the classes\n",
    "clf = Pipeline([\n",
    "        ('remove_zero_variance', VarianceThreshold()),\n",
    "        ('feature_selection', SelectKBest(f_classif, k=n_features)),\n",
    "        ('classification', RandomForestClassifier(n_estimators,\n",
    "                                                max_features = 30,\n",
    "                                                n_jobs=4,\n",
    "                                                class_weight= weights,\n",
    "                                                warm_start=False))\n",
    "])\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_test_pred = clf.predict(X)\n",
    "\n",
    "# Test on the training set:\n",
    "y_test_pred = clf.predict(X)\n",
    "print(confusion_matrix(TARGETs, y_test_pred))\n",
    "\n",
    "# Calculate the roc_auc score\n",
    "print('Overall AUC:', roc_auc_score(y, clf.predict_proba(X)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those numbers don't look too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputting the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-07T20:45:03.833822",
     "start_time": "2016-04-07T20:44:58.156417"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_probs = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\"ID\":IDs_test, \"TARGET\":y_probs})\n",
    "submission.to_csv(\"submission.csv\", index=False, float_format=\"%10.8f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
